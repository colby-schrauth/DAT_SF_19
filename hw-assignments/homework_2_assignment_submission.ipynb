{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT 19: Homework 2 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "For Homework 2, we will build on the work we did with the Titanic dataset in Homework 1. In this assignment, we will build a logistic regression model to predict passenger survival.\n",
    "\n",
    "Please do all your analysis to answer the questions below in this Jupyter notebook. Show your work.\n",
    "\n",
    "**Please submit your completed notebook by 6:00PM on Monday, January 11.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "```\n",
    "VARIABLE DESCRIPTIONS:\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "SPECIAL NOTES:\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "Age is in Years; Fractional if Age less than One (1)\n",
    " If the Age is Estimated, it is in the form xx.5\n",
    "\n",
    "With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored.  The following are the definitions used\n",
    "for sibsp and parch.\n",
    "\n",
    "Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "Other family relatives excluded from this study include cousins,\n",
    "nephews/nieces, aunts/uncles, and in-laws.  Some children travelled\n",
    "only with a nanny, therefore parch=0 for them.  As well, some\n",
    "travelled with very close friends or neighbors in a village, however,\n",
    "the definitions do not support such relations.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load libraries and dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bring dataset in as a pandas dataframe\n",
    "df = pd.DataFrame.from_csv('https://raw.githubusercontent.com/colby-schrauth/DAT_SF_19/master/data/titanic.csv',\n",
    "                           header=0, sep=',', index_col=False)\n",
    "\n",
    "test_df = pd.DataFrame.from_csv('https://raw.githubusercontent.com/colby-schrauth/DAT_SF_19/master/hw-assignments/titanic-test.csv',\n",
    "                           header=0, sep=',', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the first 5 rows to make sure I've imported the dataset properly\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the last 5 rows to make sure I've imported the dataset properly  \n",
    "df.tail(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scan the attributes of the dataframe to obtain an initial understanding of what we're working with\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a reference for the column names for easy recall\n",
    "print list(df.columns.values)\n",
    "\n",
    "# convert 'Sex' column to binary, and place values in two new columns: 'Male', 'Female'\n",
    "df['Male'] = df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "df['Female'] = df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "\n",
    "test_df['Male'] = df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "test_df['Female'] = df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check our work - print the first 5 rows to make sure I've parsed correctly\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check out work - make sure every row has been accounted for\n",
    "print df.Sex.value_counts()\n",
    "print df.Male.value_counts()\n",
    "print df.Female.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# identify the unique values in 'Embarked' and their associated frequencies\n",
    "df.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill in Embarked nulls with most common embarkment\n",
    "df['Embarked'].fillna('S', inplace=True)\n",
    "test_df['Embarked'].fillna('S', inplace=True)\n",
    "\n",
    "# check to make sure there are no more null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# break apart 'Embarked' column into binary peices, and place them in three newly created colums ('S', 'C', 'Q')\n",
    "df['EmbarkedS'] = df['Embarked'].map( {'S': 1, 'C': 0, 'Q': 0}).astype(int)\n",
    "df['EmbarkedC'] = df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 0}).astype(int)\n",
    "df['EmbarkedQ'] = df['Embarked'].map( {'S': 0, 'C': 0, 'Q': 1}).astype(int)\n",
    "\n",
    "test_df['EmbarkedS'] = df['Embarked'].map( {'S': 1, 'C': 0, 'Q': 0}).astype(int)\n",
    "test_df['EmbarkedC'] = df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 0}).astype(int)\n",
    "test_df['EmbarkedQ'] = df['Embarked'].map( {'S': 0, 'C': 0, 'Q': 1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the new columns\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill in missing age values with the median for each gender, in each class\n",
    "# start by creating an empty numpy matrix\n",
    "median_ages = np.zeros((2,3))\n",
    "median_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill the median_ages matrix with the value\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        median_ages[i,j] = df[(df['Male'] == i) & \\\n",
    "                              (df['Pclass'] == j+1)]['Age'].dropna().median()\n",
    "        \n",
    "median_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new colume titled 'AgeFill', which is equal to 'Age'\n",
    "df['AgeFill'] = df['Age']\n",
    "test_df['AgeFill'] = test_df['Age']\n",
    "\n",
    "# check my work\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull back a handful of entries where the 'Age' value is null\n",
    "df[ df['Age'].isnull() ][['Male', 'Female', 'Pclass','Age','AgeFill']].head(10)\n",
    "test_df[ test_df['Age'].isnull() ][['Male', 'Female', 'Pclass','Age','AgeFill']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill the 'AgeFill' column with the values discovered, and stored in the median_ages matrix\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        df.loc[ (df.Age.isnull()) & (df.Male == i) & (df.Pclass == j+1),\\\n",
    "                'AgeFill'] = median_ages[i,j]\n",
    "        \n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        test_df.loc[ (test_df.Age.isnull()) & (test_df.Male == i) & (test_df.Pclass == j+1),\\\n",
    "                'AgeFill'] = median_ages[i,j]\n",
    "        \n",
    "# check my work\n",
    "df[ df['Age'].isnull() ][['Male', 'Female', 'Pclass','Age','AgeFill']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new column 'AgeIsNull', which reminds us of whether or not the original 'Age' column was null\n",
    "df['AgeIsNull'] = pd.isnull(df.Age).astype(int)\n",
    "test_df['AgeIsNull'] = pd.isnull(test_df.Age).astype(int)\n",
    "\n",
    "# check my work\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create new feature called 'FamilySize' equal to # of siblings + # of parents\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creata new feature called 'Age*Class' equal to Age * Pclass\n",
    "df['Age*Class'] = df.AgeFill * df.Pclass\n",
    "test_df['Age*Class'] = test_df.AgeFill * test_df.Pclass\n",
    "\n",
    "# check my work\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Preparation** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for object data types, as these will columns will be eliminated\n",
    "df.dtypes\n",
    "df.dtypes[df.dtypes.map(lambda x: x=='object')]\n",
    "\n",
    "test_df.dtypes\n",
    "test_df.dtypes[test_df.dtypes.map(lambda x: x=='object')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop all columns that we will not use\n",
    "df = df.drop(['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Age'], axis=1)\n",
    "test_df = test_df.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Age'], axis=1)\n",
    "\n",
    "# check my work\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert back to a numpy array\n",
    "train_data = df.values\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Create a logistic regression model on the Titanic dataset to predict the survival of passengers. Show your model output. Include coefficient values.**\n",
    "\n",
    "Please see code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Which features are predictive for this logistic regression? Explain your thinking. Do not simply cite model statistics.**\n",
    "\n",
    "I believe that gender, age and passenger class are going to have the highest predictive power. At first thought, this stems from domain knowledge about the Titanic story and the individuals that were most likely to survive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Implement cross-validation for your logistic regression model. Select the number of folds. Explain your choice.**\n",
    "\n",
    "I selected five folds. I'm looking for an 80-20 split in each cross-validation instance, which leaves me with 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate the logistic regression model\n",
    "model_lr = LogisticRegression(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split features from target\n",
    "features = df.drop('Survived',axis=1)\n",
    "target = df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run the model, and get an average score for accuracy\n",
    "cross_val_score(model_lr,features,target,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test for different c values using a for loop\n",
    "c_range = range(1,31)\n",
    "c_scores = []\n",
    "\n",
    "for i in range(1,31):\n",
    "    model_lr = LogisticRegression(C=i)\n",
    "    features = df.drop('Survived',axis=1)\n",
    "    target = df.Survived\n",
    "    c_scores.append(cross_val_score(model_lr,features,target,cv=5).mean())\n",
    "\n",
    "print c_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the value of C for Logistic Regression (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(c_range, c_scores)\n",
    "plt.xlabel('Value of C for Logistic Regression')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# re-instantiate the model with an updated value for C\n",
    "model_lr = LogisticRegression(C=20).fit(features, target)\n",
    "\n",
    "# run the model, and get an average score for accuracy\n",
    "cross_val_score(model_lr,features,target,cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get Correlation Coefficient for each feature using Logistic Regression\n",
    "coeff_df = pd.DataFrame(df.columns.delete(0))\n",
    "coeff_df.columns = ['Features']\n",
    "coeff_df[\"Coefficient Estimate\"] = pd.Series(model_lr.coef_[0])\n",
    "\n",
    "# preview\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize our feature set\n",
    "n_features = StandardScaler().fit_transform(features)\n",
    "n_features = pd.DataFrame(n_features)\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get Correlation Coefficient for each feature using Logistic Regression\n",
    "coeff_df = pd.DataFrame(df.columns.delete(0))\n",
    "coeff_df.columns = ['Features']\n",
    "coeff_df[\"Coefficient Estimate\"] = pd.Series(model_lr.coef_[0])\n",
    "\n",
    "# preview\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill in missing 'Fare' value within the Test dataset\n",
    "test_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)\n",
    "\n",
    "# check my work\n",
    "test_df[ test_df['Fare'].isnull() ][['Male', 'Female', 'Pclass','Fare']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) In the hw-assignments director on the class github repo, there is a file called titanic-test.csv. What does your logistic regression model predict for these previously unseen (i.e. out of sample) passengers?**\n",
    "\n",
    "This returned a score of .5837, which is not my highest score as I've submitted to this project in the past, making me believe I did something wrong - haha!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run the test dataset through standardization and predict the outcome\n",
    "X_test = test_df.drop(\"PassengerId\",axis=1).copy()\n",
    "y_features = StandardScaler().fit_transform(X_test)\n",
    "X_test = y_features\n",
    "Y_pred = model_lr.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('titanic.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
