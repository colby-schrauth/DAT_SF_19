{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT 19: Homework 3 Assignment - Clustering with K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "In this homework assignment, we will get practice with our first unsupervised learning technique, clustering. We will analyze wholesale purchases by 440 clients of a wholesale distributor. \n",
    "\n",
    "Please do all your analysis to answer the questions below in this Jupyter notebook. Show your work.\n",
    "\n",
    "**Please submit your completed notebook by 6:30PM on Wednesday, January 20.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "The [Wholesale Customers dataset](http://archive.ics.uci.edu/ml/datasets/Wholesale+customers) and a description of the data is available from the UCI ML Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Load the dataset. Check for missing values, perform any normalization that you think is necessary (remember that K-means uses the Euclidean Distance function).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/00292/Wholesale%20customers%20data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Look at column names\n",
    "print list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lower-case all DataFrame column names\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "#List the column names and show dataframe attributes\n",
    "print list(df.columns.values)\n",
    "print \"\\n...\\n\"\n",
    "print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get quick count of rows in the DataFrame\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#List unique values in the categorical variables\n",
    "print \"channel unique values:\", pd.unique(df.channel.ravel())\n",
    "print \"region unique values:\", pd.unique(df.region.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#List count of each unique value in each categorical variable\n",
    "print df['channel'].value_counts()\n",
    "print df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Rename channel column for easy associating once converted to binary\n",
    "df = df.rename(columns={'channel' : 'channel_1'})\n",
    "\n",
    "#Convert categorical variables to binary\n",
    "df['channel_1'] = df.channel_1.map({1:1, 2:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create two new columns for Region and convert to binary\n",
    "df['region_3'] = df['region'].map( {1:0, 2:0, 3:1} )\n",
    "df['region_1'] = df['region'].map( {1:1, 2:0, 3:0} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Order columns\n",
    "cols = list(df)\n",
    "cols.insert(1, cols.pop(cols.index('region_3')))\n",
    "cols.insert(2, cols.pop(cols.index('region_1')))\n",
    "df = df.ix[:, cols]\n",
    "\n",
    "#Remove the original 'region' column\n",
    "del df['region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#StandardScaler practice\n",
    "\n",
    "#std_scale = StandardScaler().fit(df['fresh'])\n",
    "#df_std = std_scale.transform(df['fresh'])\n",
    "#print('Mean after standardization:\\nfresh={:.2f}'.format(df_std.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1) Look at the dataset. There are both continuous and categorical variables. What are the categorical variables? From a business perspective, what do those categorical variables represent?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The categorical variables are 'Channel' and 'Region'. 'Channel' aligns to one of two verticals: Retail or Hotel/Restaurant. 'Region' aligns to one of three locations: Other, Oporto or Lisbon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2) What results might we expect from the k-means clustering if we were to run it on the dataset as-is? Explain your thinking in words.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Because K-means uses the mean, the binary features will pull the centroids closer to each other, neglecting the importance of a cluster center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Using ONLY the continuous features in the dataset, apply the K-means algorithm to find clusters in the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.ix[:,3:9]\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km = KMeans()\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers = km.cluster_centers_\n",
    "centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1) Plot the Silhouette Coefficient as a function of the number of clusters (remember that you set the number of clusters as an input to K-means).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = km.labels_\n",
    "silhouette_score(X,labels,metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manykm = KMeans(2)\n",
    "manykm.fit(X)\n",
    "manycenters = manykm.cluster_centers_\n",
    "\n",
    "manylabels = manykm.labels_\n",
    "silhouette_score(X,manylabels,metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,2):\n",
    "    # select only data observations with cluster label == i\n",
    "    ds = X[np.where(labels==i)]\n",
    "    # plot the data observations\n",
    "    plt.plot(ds[:,0],ds[:,1],'o')\n",
    "    # plot the centroids\n",
    "    lines = plt.plot(manycenters[i,0],manycenters[i,1],'kx')\n",
    "    # make the centroid x's bigger\n",
    "    plt.setp(lines,ms=15.0)\n",
    "    plt.setp(lines,mew=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2) What is the ideal value for k, the number of clusters? Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2, because it provides the highest Silhouette value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3) How does your answer for 3.2 compare with your thoughts from 2.2 above?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your text based answer here. Feel free to convert this cell to markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Credit Questions\n",
    "**The following questions are strongly encouraged, but not required for this homework assignment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Read the scikit-learn user guide section about [clustering](http://scikit-learn.org/stable/modules/clustering.html). Pay particular attention to the section about [assumptions](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html#example-cluster-plot-kmeans-assumptions-py).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) PCA & PLOTTING:** <br> With six continuous features, plotting our clusters in two dimensions will be challenging. We can use [Principal Components Analysis](http://scikit-learn.org/stable/modules/decomposition.html#pca) and then plot only the \"top two\" dimensions. More technically, these are the dimensions that capture most of the variance in our data set. For this extra credit question, read about [PCA in the sklearn.decomposition module](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html), apply it to the wholesale dataset, repeat the k-means clustering, and plot your results using only the top two principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here, should you choose to attempt it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
